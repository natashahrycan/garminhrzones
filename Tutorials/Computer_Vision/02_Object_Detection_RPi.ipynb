{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natashahrycan/garminhrzones/blob/main/Tutorials/Computer_Vision/02_Object_Detection_RPi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMThysV-qChJ"
      },
      "source": [
        "# Object Detection with an RPi\n",
        "\n",
        "This tutorial will introduce you to some concepts you need to know to understand how good (or bad) and object detection model is detecting objects.\n",
        "\n",
        "## What will you learn in this lesson?\n",
        "1. How to connect a camera to a Raspberry Pi (a.k.a RPi).\n",
        "2. Use a pre-trained model to perform object detection.\n",
        "3. Visualize the detections (and what are bounding boxes).\n",
        "\n",
        "\n",
        "Aditionally, you can analyze how good (or bad) is your model with metrics (IoU, precision and recall). Please visit [this tutorial](https://github.com/rafaelpadilla/Object-Detection-Metrics) by Radael Padilla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OegblT7UqRUZ"
      },
      "source": [
        "## 1. How to connect a camera to a Raspberry Pi?\n",
        "Quite easy, my friend. Grab your camera, your Raspberry Pi and follow [this tutorial on how to install a camera on a Raspberry Pi](https://www.youtube.com/watch?v=GtNkFnTPhyo). If you need more information, you can always visit the [official website of Raspberry Pi](https://www.raspberrypi.com/documentation/computers/camera_software.html#rpicam-apps).\n",
        "\n",
        "Here are some commands used in the video:\n",
        "```\n",
        "$ rpicam-hello                       # to see the camera preview\n",
        "$ rpicam-jpeg --output test.jpg      # to capture a picture and name it test.jpg\n",
        "$ rpicam-vid -t 10s -o video.h264    # to record a 10 second h264 video\n",
        "```\n",
        "\n",
        "We can also test the OpenCV preview. For this, you can copy the code below into a Python script and run it in the terminal of the Raspbery Pi.\n",
        "```\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(0)\n",
        "ret, frame = cap.read()\n",
        "cv2.imshow(\"Test\", frame)\n",
        "cv2.waitKey(0)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "```\n",
        "\n",
        "üîç An important detail is that if you want to work with live-detections on the Raspberry Pi, you will need to work locally. This just means that you cannot run the code in Google Colab, for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nCWDM0GlHAm"
      },
      "source": [
        "## 2. Live object detection with a Raspberry Pi\n",
        "Once the camera is connected, we can test if our Raspberry Pi can detect objects in real time.\n",
        "\n",
        "First, we will install necessary dependencies and update the system. Run the following lines in the terminal.\n",
        "\n",
        "```\n",
        "$ sudo apt update\n",
        "$ sudo apt install python3-pip\n",
        "$ pip3 install opencv-python numpy torch torchvision torchaudio\n",
        "$ pip3 install ultralytics  # for YOLOv8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will load the pre-trained model (in this case we chose Yolov8, but feel free to experiment with other versions!).\n",
        "\n",
        "You can copy and paste the following lines into a Python script and run it from the terminal to perform live object detection.\n",
        "\n",
        "```\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load a light model\n",
        "model = YOLO(\"yolov8n.pt\")  # n stands for the \"nano\" version, very lightweight\n",
        "\n",
        "# Start camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLO expects RGB\n",
        "    results = model.predict(source=frame, show=True, conf=0.3)\n",
        "\n",
        "    # Press 'q' to quit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "4UQoKz__AXmG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHC61tMQm5Ku"
      },
      "source": [
        "### If you're still looking for more...\n",
        "\n",
        "I have found a couple of interesting options for you to explore more, for example [a tutorial for traffic sign detection](https://colab.research.google.com/github/dctian/DeepPiCar/blob/master/models/object_detection/code/tensorflow_traffic_sign_detection.ipynb), or this [full tutorial](https://www.digikey.my/en/maker/projects/how-to-perform-object-detection-with-tensorflow-lite-on-raspberry-pi/b929e1519c7c43d5b2c6f89984883588) of Object Detection in RPis.\n",
        "\n",
        "It may be useful as well to know how to install different versions of Python in an RPi if you're working with Tensorflow, for example. [This nice tutorial](https://www.youtube.com/watch?v=QdlopCUuXxw) can help you if you have that problem.\n",
        "\n",
        "Remember, it's normal to get errors while trying something new. Google will be your best friend to find alternative solutions or paths. The best solution is the one that works ü¶æ"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzmDeSiMzV52RiZxI4BkFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}